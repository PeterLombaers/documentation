---
# Copyright Yahoo. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Streaming Search"
redirect_from:
- /documentation/streaming-search.html
---

<p>Search engines make queries fast by creating indexes over the stored data.
While the indexes cost extra resources to build and maintain, this is usually
a good tradeoff because they make queries so much cheaper. However, this
does not hold for use cases where the data is split into many small subsets
where each query just searches one (or a few) of these subsets, the canonical
example being <em>personal indexes</em> where a user only searches her own data.</p>

<p>For such use cases, Vespa provides <i>streaming search</i>
- a mode where only the raw data of the documents is
<a href="proton.html#document-store">stored</a> and searches are implemented
by streaming - no indexes required. In addition, attributes
are also only stored on disk so that the only data needed in memory is
45 bytes per document, meaning that streaming mode lets you store billions of documents
on each node.</p>

<p>This is especially important in personal data applications using vector embeddings,
which otherwise require a lot of memory and require ANN to perform well,
which is often unsuited for searching personal data as they don't surface
all the most relevant documents.</p>

<p>Streaming mode is suitable when subsets are <em>on average</em> small compared
to the entire corpus. Vespa delivers low query latency also for the occasional large
subset (say, users with huge amounts of data) by automatically sharding such data groups
over multiple content nodes, searched in parallel.</p>

<p>Streaming search uses the same implementation of most features in Vespa, including ranking,
matching and grouping, and supports the same features, with these exceptions:</p>

<ul>
    <li><a href="linguistics.html#stemming">stemming</a> is not supported with streaming.</li>
    <li>Streaming search supports a wider range of matching options (such as substring and prefix), and
        these can be specified either at query time or at configuration time.
</ul>


<h2 id="using-streaming-search">Using streaming search</h2>

<p>
These are the steps required to use streaming search,
based on the <a href="https://github.com/vespa-engine/sample-apps/tree/master/album-recommendation">
sample apps</a>:
</p>
<ol>
  <li>
    Set indexing mode to <a href="reference/services-content.html#document">streaming</a>:
<pre>
&lt;content id="mycluster" version="1.0"&gt;
    &lt;documents&gt;
        &lt;document type="music" <span class="pre-hilite">mode="streaming"</span> /&gt;
</pre>
  </li>

    <li>Use
    <a href="documents.html">document IDs</a> which contains a <i>group</i> value specifying
    the small subset the document belongs to (usually a userid). These have the form
        <code>id:my-namespace:music:<b>g=my-userid</b>:my-localid</code>
    and when represented as paths in <a href="document-v1-api-guide.html">document/v1</a> requests,
    <code>document/v1/my-namespace/music/<span class="pre-hilite">group/my-userid</span>/my-localid</code>
  </li>

  <li>
    Specify the subset to search using the query parameter
    <a href="reference/query-api-reference.html#streaming.groupname">streaming.groupname</a>.
  </li>

</ol>


<h2 id="matching-options-in-streaming-search">Matching options in streaming search</h2>

<p>Streaming search offers more flexibility in matching text fields: Match settings
can be specified at query time on any text field, and fields marked with <code>indexing: index</code>
supports prefix and substring matching.</p>

<p>To specify match settings at query time in YQL:</p>
<pre>
select * from sources * where artist contains ({prefix:true}"col")
select * from sources * where artist contains ({substring:true}"old")
select * from sources * where artist contains ({suffix:true}"play")
</pre>

<p>To specify a default match setting for a field in the schema:</p>

<pre>
field artist type string {
    indexing: summary | index
    <a href="schemas.html#match">match</a>: prefix
}
</pre>


<h2 id="streaming-search-grouping-extensions">Streaming search grouping extension</h2>

<p><a href="grouping.html">Grouping</a> works as normal with streaming search but offers some additional features.</p>

<h3 id="grouping-over-all-documents">Grouping over all documents</h3>

<p>Since streaming search "looks at" all documents matching the group name/selection
  regardless of the query, it is possible to group over all those documents and not just the ones
  matching the query. This is done by using <code>where(true)</code> in the grouping expression:

<pre>all( where(true) all(group(myfield) each(output(count()))) )</pre>

<p>When doing this, relevancy is not calculated for groups, as only matched hits have relevance.</p>

<h3 id="docidnsspecific-function"><code>docidnsspecific</code> function</h3>

<p>The <code>docidnsspecific</code> function returns the docid without namespace.</p>
<pre>all( group(docidnsspecific()) each(output(count())) )</pre>



<h2 id="resource-usage-with-streaming-search">Resource usage with streaming search</h2>

<p><b>Memory</b>: Streaming search requires 45 bytes of memory per document regardless of the document content.</p>

<p><b>Disk</b>: Streaming search requires disk space to store the raw document data in compressed form.
The size is dependent on the actual data but can be extrapolated linearly eith the number of documents.</p>


<h2 id="query-tuning-in-streaming-search">Query tuning in streaming search</h2>

<p>Streaming search is a <a href="visiting.html">visit</a> operation.
Parallelism is configured using <a href="reference/services-content.html#persistence-threads">persistence-threads</a>:
</p>

<pre>
&lt;persistence-threads count='8'/&gt;
&lt;visitors thread-count='8'/&gt;
</pre>

<p>On <a href="https://cloud.vespa.ai/">Vespa Cloud</a>,
this number is set automatically to match the number of VCPUs set in
<a href="https://cloud.vespa.ai/en/reference/services#resources">resources</a>.
If you cannot get lower latency by increasing vcpus, it means your streaming searches have become
IO bound.</p>


<h3 id="tuning-summary-store-direct-io-and-cache">Tuning summary store: Direct IO and cache</h3>

<p>For better control of memory usage, use direct IO for reads when summary cache is enabled -
this makes the OS buffer cache size smaller and more predictable performance.
The summary cache will cache recent entries and increase performance for users or groups doing repeated accesses.
This sets aside 1 GB for summary cache.
</p>
<pre>
&lt;engine&gt;
  &lt;proton&gt;
    &lt;tuning&gt;
      &lt;searchnode&gt;
        &lt;summary&gt;
          &lt;io&gt;
            &lt;write&gt;directio&lt;/write&gt;
<span class="pre-hilite">            &lt;read&gt;directio&lt;/read&gt;</span>
          &lt;/io&gt;
          &lt;store&gt;
<span class="pre-hilite">            &lt;cache&gt;
              &lt;maxsize&gt;1073741824&lt;/maxsize&gt;
            &lt;/cache&gt;</span>
</pre>
