---
# Copyright Yahoo. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
title: "Multinode systems"
redirect_from:
- /documentation/multinode-systems.html
- /en/multinode-systems.html
- /en/vespa-quick-start-multinode-aws.html
---

<p>
  A Vespa <em>system</em> consists of one or more stateless and stateful clusters configured by an application package.
  A Vespa system is configured and managed through an admin cluster as shown below.
</p>
<img src="/assets/img/vespa-overview.svg" width="825px" height="auto" alt="Vespa Overview" />
<p>
  All nodes of a Vespa system have the same software installed.
  Which processes are started on each node and how they are configured
  is determined by the admin cluster from the specification given in
  <a href="../reference/services.html">services.xml</a> in the application package.
</p>



<h2 id="creating-a-multinode-system-from-a-sample-application">
  Creating a multinode system from a sample application</h2>
<p>
  To create a fully functional production ready multinode system from a single-node sample application,
  follow these steps (also see <a href="#next-steps">next steps</a>):
</p>
<ol>
  <li>Add an <a href="../reference/services-admin.html">admin cluster</a> in services.xml:
<pre>{% highlight xml %}
<services version="1.0">
    <admin version="2.0">
        <configservers>
            <configserver hostalias="node0"/>
            <configserver hostalias="node1"/>
            <configserver hostalias="node2"/>
        </configservers>
        <cluster-controllers>
            <cluster-controller hostalias="node0"/>
            <cluster-controller hostalias="node1"/>
            <cluster-controller hostalias="node2"/>
        </cluster-controllers>
        <slobroks>
            <slobrok hostalias="node0" />
            <slobrok hostalias="node1" />
            <slobrok hostalias="node2" />
        </slobroks>
        <adminserver hostalias="node3"/>
    </admin>
{% endhighlight %}</pre>
  </li>
  <li>Install the Vespa packages or the <em>vespaengine/vespa</em> Docker image on all the nodes.</li>
  <li>Run
<pre>
$ echo "override VESPA_CONFIGSERVERS [configserver-hostnames]" >> $VESPA_HOME/conf/vespa/default-env.txt
</pre>
    where <code>[configserver-hostnames]</code> is replaced by the full hostname of the config server
	  (or a comma-separated list if multiple).
  </li>
  <li>
    Add these nodes to the container and content clusters
    by adding more <code>node</code> tags in <em>services.xml</em>.
  </li>
  <li>Add the same nodes to <em>hosts.xml</em>.</li>
  <li>Start Vespa on the nodes</li>
</ol>
<p>
  See below for AWS examples.
  Refer to <a href="configuration-server.html">configuration server operations</a> for troubleshooting.
</p>



<h2 id="aws-ec2">AWS EC2</h2>
<p>
  The following is a procedure to set up a multinode application on AWS EC2 instances.
  Please run the procedure in
  <a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode-HA">multinode-HA</a>
  first, to get familiar with the different Vespa concepts before running the AWS procedure below.
  This procedure will use the name number of host, 10, and set up the same application.
</p>
{% include important.html content="Note the use of <code>sudo</code> in the commands below." %}

{% include note.html content="The procedure below is a bare minimum, for educational purposes.
Make sure to use AWS instance types suitable for the application load,
and implement security mechanisms of choice." %}


<h3 id="node-setup">Node setup</h3>
<ul>
  <li>
    Provision nodes:
    <ul>
      <li>Find AMI at <a href="https://centos.org/download/aws-images/">CentOS AWS AMI Cloud Images</a> -
        this procedure is tested with <em>CentOS Stream 8	us-east-1	x86_64 ami-0ee70e88eed976a1b</em>
        and vespa-8.30.50.</li>
      <li>Use minimum <em>t2.medium</em> instances.</li>
      <li>Let AWS create a security group for the nodes, or use an existing one.</li>
      <li>Make sure to check for SSH traffic, for host login.</li>
      <li>Launch 10 instances - the 3 first will be Vespa config server nodes, the 7 last Vespa nodes.
        Write down the 3 config server hostnames, like <code>ip-172-31-23-128.ec2.internal</code>,
        <code>ip-172-31-29-111.ec2.internal</code>, <code>ip-172-31-20-49.ec2.internal</code>.
        The hostnames must be the same as returned by the <code>hostname</code> command.
      </li>
    </ul>
  </li>
  <li>
    Security group setup:
    <ul>
      <li>Click the Security Group for the nodes just provisioned (under the security tab),
        then <em>Edit inbound rules</em>.
        Add <em>All TCP</em> for port range 0-65535, specifying the name of the current Security Group as the Source.
        This lets the hosts communicate with each other.
      </li>
    </ul>
  </li>
  <li>
    On each of the 10 hosts,
    install Vespa using the <a href="../build-install-vespa.html#rpms">install procedure</a>:
    <pre>
$ sudo dnf config-manager \
  --add-repo https://raw.githubusercontent.com/vespa-engine/vespa/master/dist/vespa-engine.repo
$ sudo dnf config-manager --enable powertools
$ sudo dnf install -y epel-release
$ sudo dnf install -y vespa
$ export VESPA_HOME=/opt/vespa
</pre>
  </li>
  <li>
    On all the 10 hosts, set up the environment using the config server host list:
<pre>
$ echo "override VESPA_CONFIGSERVERS" \
  "ip-172-31-23-128.ec2.internal,ip-172-31-29-111.ec2.internal,ip-172-31-20-49.ec2.internal" \
  | sudo tee -a $VESPA_HOME/conf/vespa/default-env.txt
</pre>
    It is required that all nodes, both config server and Vespa nodes,
    have the same setting for <code>VESPA_CONFIGSERVERS</code>.
  </li>
</ul>

<h3 id="config-server-cluster-setup">Config server cluster setup</h3>
<ul>
  <li>
    Start the 3-node config server cluster:
<pre>
$ sudo /opt/vespa/bin/vespa-start-configserver
</pre>
  </li>
  <li>
    Verify the config cluster is running - on one of the config server nodes:
    <pre>
$ for configserver in \
  ip-172-31-23-128.ec2.internal \
  ip-172-31-29-111.ec2.internal \
  ip-172-31-20-49.ec2.internal \
  do curl -s http://$configserver:19071/state/v1/health | head -5; done

{
  "time" : 1660034756595,
  "status" : {
    "code" : "up"
  },
{
  "time" : 1660034756607,
  "status" : {
    "code" : "up"
  },
{
  "time" : 1660034756786,
  "status" : {
    "code" : "up"
  },
</pre>
    A successful config server start will log an entry like:
<pre>
$ /opt/vespa/bin/vespa-logfmt | grep "Application config generation"

  [2022-08-09 08:29:38.684] INFO    : configserver
  Container.com.yahoo.container.jdisc.ConfiguredApplication
  Switching to the latest deployed set of configurations and components.
  Application config generation: 0
</pre>
    Do not continue setup before the config server cluster is successfully started.
    Resources: <a href="https://vespa.ai/resources#troubleshooting-startup-multinode">
    Troubleshooting startup - multinode</a> and
    <a href="configuration-server.html#start-sequence">config server start sequence</a>.
  </li>
  <li>
    Start Vespa services on the 3 config server nodes - this starts basic Vespa services like log forwarding:
<pre>
$ sudo /opt/vespa/bin/vespa-start-services
</pre>
    <em>/opt/vespa/logs/vespa/vespa.log/vespa.log</em> will now contain messages for <code>APPLICATION_NOT_LOADED</code>,
    this is normal until an application is deployed (next section).
  </li>
</ul>


<h3 id="configure-application">Configure application</h3>
<ul>
  <li>Configure the sample application - on one of the config server nodes:
<pre>
$ sudo dnf install -y git
$ git clone https://github.com/vespa-engine/sample-apps.git && \
  cd sample-apps/examples/operations/multinode-HA
</pre>
  </li>
  <li>Edit <em>hosts.xml</em> - replace the <em>nodeX.vespanet</em> names.
    Let the 3 first hosts be the config server hosts above, the 7 rest the Vespa hosts - example:
<pre>{% highlight xml %}
      <?xml version="1.0" encoding="utf-8" ?>
      <hosts>
    <!-- 3 config server nodes -->
    <host name="ip-172-31-23-128.ec2.internal">
        <alias>node0</alias>
    </host>
    <host name="ip-172-31-29-111.ec2.internal">
        <alias>node1</alias>
    </host>
    <host name="ip-172-31-20-49.ec2.internal">
        <alias>node2</alias>
    </host>


        <!-- 7 Vespa nodes -->
    <host name="ip-172-31-29-34.ec2.internal">
        <alias>node3</alias>
    </host>

    <host name="ip-172-31-19-21.ec2.internal">
        <alias>node4</alias>
    </host>
    <host name="ip-172-31-31-216.ec2.internal">
        <alias>node5</alias>
    </host>

    <host name="ip-172-31-24-59.ec2.internal">
        <alias>node6</alias>
    </host>
    <host name="ip-172-31-27-128.ec2.internal">
        <alias>node7</alias>
    </host>

    <host name="ip-172-31-24-34.ec2.internal">
        <alias>node8</alias>
    </host>
    <host name="ip-172-31-24-155.ec2.internal">
        <alias>node9</alias>
    </host>
</hosts>
{% endhighlight %}</pre>
  </li>
  <li>Deploy the application:
<pre>
$ zip -r - . -x "img/*" "scripts/*" "pki/*" "tls/*" README.md .gitignore | \
  curl --header Content-Type:application/zip --data-binary @- \
  localhost:19071/application/v2/tenant/default/prepareandactivate
</pre>
    Expected output:
    <pre>{% highlight json %}
{
    "log": [],
    "tenant": "default",
    "url": "http://localhost:19071/application/v2/tenant/default/application/default/environment/prod/region/default/instance/default",
    "message": "Session 2 for tenant 'default' prepared and activated.",
    "configChangeActions": {
        "restart": [],
        "refeed": [],
        "reindex": []
    }
}
{% endhighlight %}</pre>
  </li>
</ul>




<h3 id="vespa-nodes-setup">Vespa nodes setup</h3>
<ul>
  <li>
    Start Vespa on the 7 hosts:
<pre>
$ sudo /opt/vespa/bin/vespa-start-services
</pre>
  </li>
  <li>
    Validate the installation.
    Use the <a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode-HA">
    multinode-HA</a> steps to check the health interfaces on all 10 nodes.
    Note that in this guide, the ports are not mapped through a Docker container,
    so the native Vespa ports should be used, like:
<pre>
$ curl http://localhost:8080/state/v1/health

{
  "time" : 1660038306465,
  "status" : {
    "code" : "up"
  },
</pre>
    Refer to the sample application ports:
    <img src="https://github.com/vespa-engine/sample-apps/raw/master/examples/operations/multinode-HA/img/multinode-HA.svg"
    alt="Sample application ports"/>
  </li>
</ul>



<h3 id="aws-ec2-singlenode">AWS EC2 singlenode</h3>
<p>
  This is a variant of the multinode install, using only one host,
  running both a config server and the other Vespa services on the same node.
</p>
<ul>
  <li>
    Provision a node, minimum a <em>t2.large</em>.
    Get its hostname for use in <code>VESPA_CONFIGSERVERS</code>:
<pre>
$ hostname
</pre>
  </li>
  <li>
    Install Vespa:
<pre>
$ sudo dnf config-manager \
  --add-repo https://raw.githubusercontent.com/vespa-engine/vespa/master/dist/vespa-engine.repo
$ sudo dnf config-manager --enable powertools
$ sudo dnf install -y epel-release
$ sudo dnf install -y vespa
$ export VESPA_HOME=/opt/vespa
$ echo "override VESPA_CONFIGSERVERS ip-172-31-95-248.ec2.internal" | \
  sudo tee -a $VESPA_HOME/conf/vespa/default-env.txt
</pre>
  </li>
  <li>
    Get a sample application:
<pre>
$ sudo dnf install -y git
$ git clone https://github.com/vespa-engine/sample-apps.git && cd sample-apps/album-recommendation
</pre>
  </li>
  <li>
    Start the config server, check health port after a few seconds:
<pre>
$ sudo /opt/vespa/bin/vespa-start-configserver
$ curl localhost:19071/state/v1/health | head -5
</pre>
  </li>
  <li>
    Deploy the sample application:
<pre>
$ zip -r - . -x "img/*" "scripts/*" "pki/*" "tls/*" README.md .gitignore | \
  curl --header Content-Type:application/zip --data-binary @- \
  localhost:19071/application/v2/tenant/default/prepareandactivate
</pre>
  </li>
  <li>
    Start Vespa, check container node health after some seconds:
<pre>
$ sudo /opt/vespa/bin/vespa-start-services
$ curl localhost:8080/state/v1/health | head -5
</pre>
  </li>
</ul>



<h2 id="aws-ecs">AWS ECS</h2>
<p>
  This section explains how to set up a multinode system by running the Vespa
  Docker image on <a href="https://us-east-1.console.aws.amazon.com/ecs">AWS ECS</a>.
  See <a href="../getting-started.html">Getting Started</a> for troubleshooting, next steps and other guides.
</p>


<h3 id="create-a-10-node-ecs-cluster">Create a 10-node ECS cluster</h3>
    <ul>
      <li>Log in to AWS and the EC2 Container Service.
        Click <em>Cluster &gt; Create Cluster &gt; EC2 Linux + Networking</em>, using the defaults and:
        <table class="table">
          <thead></thead>
          <tbody>
          <tr><th>Cluster name</th><td>vespa</td></tr>
          <tr><th>EC2 instance type</th><td>t2.medium</td></tr>
          <tr><th>Number of instances</th><td>10</td></tr>
          <tr><th>Key pair</th><td><i>Select or create your keypair</i></td></tr>
          <tr><th>Security group inbound rules - port range</th><td>0 - 65535</td></tr>
          </tbody>
        </table>
      </li>
      <li>Click <em>Create</em> and wait for the tasks to succeed</li>
      <li>Click <em>View Cluster</em></li>
    </ul>


<h3 id="configure-ecs-instances">Configure ECS instances</h3>
<ul>
  <li>Click the <em>ECS Instances tab</em> - this should list 10 container instances</li>
  <li>Select the 3 first Container Instance checkboxes,
    then <em>Actions -> View/Edit attributes</em></li>
  <li>Click <em>Add attribute</em>.
    Set <code>Name=type</code> and <code>Value=configserver</code>
    and click the green checkbox on the right.
    Then click <em>Close</em>.
  </li><li>Select the next 7 Container instance checkboxes,
  then <em>Actions -> View/Edit attributes</em></li>
  <li>Click <em>Add attribute</em>.
    Set <code>Name=type</code> and <code>Value=services</code>
    and click the green checkbox on the right. Then click <em>Close</em></li>
  <li>Click on the first <em>Container Instance</em> name</li>
  <li>Take a note of the 3 config server Private DNS addresses,
    e.g. <code>ip-10-0-0-128.ec2.internal,ip-10-0-1-142.ec2.internal,ip-10-0-1-171.ec2.internal</code>,
    as these will be used next.</li>
</ul>


<h3 id="start-the-config-server-task">Start the config server task</h3>
<ul>
  <li>Click <em>Task Definitions &gt; Create new Task Definition &gt; EC2 &gt; Next step</em></li>
  <li>Click <em>Configure via JSON</em> and replace the content with
    (note the comma-separated hostnames of the config servers addresses):
<pre>
{
    "networkMode": "host",
    "containerDefinitions": [
        {
            "name": "configserver",
            "environment": [
                {
                    "name": "VESPA_CONFIGSERVERS",
                    "value": "<span class="pre-hilite">ip-10-0-0-128.ec2.internal,ip-10-0-1-142.ec2.internal,ip-10-0-1-171.ec2.internal</span>"
                }
            ],
            "image": "vespaengine/vespa",
            "command": [
                "configserver"
            ],
            "privileged": true,
            "memoryReservation": 1024
        }
    ],
    "placementConstraints": [
        {
            "expression": "attribute:type == configserver",
            "type": "memberOf"
        }
    ],
    "family": "configserver"
}
</pre>
  </li>
  <li>Click <em>Save &gt; Create</em></li>
  <li>Choose <em>Actions -> Run task</em> and configure:
    <table class="table">
      <thead></thead><tbody>
    <tr><th>Launch type</th><td>EC2</td></tr>
    <tr><th>Cluster</th><td>vespa</td></tr>
    <tr><th>Number of tasks</th><td>3</td></tr>
    <tr><th>Placement templates</th><td>One Task Per Host</td></tr>
    </tbody>
    </table>
  </li>
  <li>Click <em>Run Task</em></li>
  <li>Validate that the config servers started successfully -
    use the same procedure as for <a href="#config-server-cluster-setup">EC2 instances</a>,
    checking <em>http://$configserver:19071/state/v1/health</em>.
    Do not continue before successfully validating this.
  </li>
</ul>


<h3 id="configure-application-ecs">Configure application - ECS</h3>
<p>
  This step is the same as for <a href="#configure-application">EC2 instances</a> -
  modify <em>hosts.xml</em> and deploy the application.
</p>


<h3 id="start-the-services-tasks">Start the services tasks</h3>
<ul>
  <li>Click <em>Task Definitions &gt; Create new Task Definition &gt; EC2 &gt; Next step</em></li>
  <li>Click <em>Configure via JSON</em> and replace the content with (using the same 3 config server addresses):
<pre>
{
    "networkMode": "host",
    "containerDefinitions": [
        {
            "name": "services",
            "environment": [
                {
                    "name": "VESPA_CONFIGSERVERS",
                    "value": "<span class="pre-hilite">ip-10-0-0-128.ec2.internal,ip-10-0-1-142.ec2.internal,ip-10-0-1-171.ec2.internal</span>"
                }
            ],
            "image": "vespaengine/vespa",
            "command": [
                "services"
            ],
            "privileged": true,
            "memoryReservation": 1024
        }
    ],
    "placementConstraints": [
        {
            "expression": "attribute:type == services",
            "type": "memberOf"
        }
    ],
    "family": "services"
}
</pre>
  </li>
  <li>Click <em>Save &gt; Create</em></li>
  <li>Choose <em>Actions -> Run task</em> and configure:
    <table class="table">
      <thead></thead><tbody>
    <tr><th>Launch type</th><td>EC2</td></tr>
    <tr><th>Cluster</th><td>vespa</td></tr>
    <tr><th>Number of tasks</th><td>7</td></tr>
    <tr><th>Placement templates</th><td>One Task Per Host</td></tr>
    </tbody>
    </table>
  </li>
  <li>Click <em>Run Task</em></li>
  <li>
    Validate startup.
    This step is the same as for <a href="#vespa-nodes-setup">EC2 instances</a>.
    ToDo: check port mappings / command.
  </li>
</ul>



<h2 id="log-collection">Log collection</h2>
<p>
  Logs are automatically collected from all nodes in real time to the admin node listed as <code>adminserver</code>.
  To view log messages from the system,
  run <a href="../reference/vespa-cmdline-tools.html#vespa-logfmt">vespa-logfmt</a> on this node.
</p>



<h2 id="making-changes-to-live-systems">Making changes to live systems</h2>
<p>
  To change the system, deploy the changed application to the admin cluster.
  The admin cluster will automatically change the participating nodes as necessary.
  It is safe to do this while serving live query and write traffic.
  In some cases the admin cluster will report that some processes must be restarted to make the change effective.
  To avoid query or write traffic disruption,
  such restarts must be done on one node at the time,
  waiting until the node is fully up before restarting the next one.
</p>



<h2 id="notes">Notes</h2>
<ul>
  <li>
    Host login example, without ssh-agent:
    <code>SSH_AUTH_SOCK=/dev/null ssh -i mykeypair.pem centos@ec2-100-24-25-186.compute-1.amazonaws.com</code>
  </li>
</ul>



<h2 id="next-steps">Next steps</h2>
<ul>
<li>
  The <a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode">multinode</a>
  sample application is a useful starting point for setting up a system
  and run some basic tests to get familiar with Vespa APIs and interfaces.
</li>
<li>
  <a href="https://github.com/vespa-engine/sample-apps/tree/master/examples/operations/multinode-HA">multinode-HA</a>
  is a high-availability multi-node template - use this as a basis for the final configuration.
</li>
</ul>
